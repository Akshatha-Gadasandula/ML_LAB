{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOtw29b+62vcZIkrHY/s1s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akshatha-Gadasandula/ML_LAB/blob/main/ML_Assignment_2_(150).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUlU1bGg8Nyy",
        "outputId": "485672c7-1368-400d-ee85-ca0669762073"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (569, 30)\n",
            "Classes: [0 1]\n",
            "\n",
            "Baseline Accuracy: 0.956140350877193\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.90      0.94        42\n",
            "           1       0.95      0.99      0.97        72\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n",
            "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
            "\n",
            "Best Parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 50, 'subsample': 0.8}\n",
            "Best Cross-Validation Accuracy: 0.9692546764261647\n",
            "\n",
            "Tuned Accuracy: 0.956140350877193\n",
            "\n",
            "Classification Report (Tuned):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.93      0.94        42\n",
            "           1       0.96      0.97      0.97        72\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[39  3]\n",
            " [ 2 70]]\n"
          ]
        }
      ],
      "source": [
        "# Machine Learning Assignment 2\n",
        "# Research Paper : “XGBoost: A Scalable Tree Boosting System”\n",
        "#  -by Tianqi Chen and Carlos Guestrin\n",
        "#  -Published in Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD ’16), 2016.\n",
        "# Dataset: Breast Cancer (from sklearn)\n",
        "\n",
        "\n",
        "# Step 1: Import libraries-\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "# Step 2: Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "print(\"Dataset shape:\", X.shape)\n",
        "print(\"Classes:\", np.unique(y))\n",
        "\n",
        "\n",
        "# Step 3: Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "\n",
        "# Step 4: Baseline Model (XGBoost Default)\n",
        "xgb_default = XGBClassifier(eval_metric='logloss')\n",
        "xgb_default.fit(X_train, y_train)\n",
        "\n",
        "y_pred_default = xgb_default.predict(X_test)\n",
        "print(\"\\nBaseline Accuracy:\", accuracy_score(y_test, y_pred_default))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_default))\n",
        "\n",
        "\n",
        "# Step 5: Hyperparameter Tuning (GridSearch)\n",
        "params = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=XGBClassifier( eval_metric='logloss'),\n",
        "    param_grid=params,\n",
        "    scoring='accuracy',\n",
        "    cv=3,\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nBest Parameters:\", grid.best_params_)\n",
        "print(\"Best Cross-Validation Accuracy:\", grid.best_score_)\n",
        "\n",
        "\n",
        "# Step 6: Tuned Model\n",
        "xgb_tuned = grid.best_estimator_\n",
        "y_pred_tuned = xgb_tuned.predict(X_test)\n",
        "\n",
        "print(\"\\nTuned Accuracy:\", accuracy_score(y_test, y_pred_tuned))\n",
        "print(\"\\nClassification Report (Tuned):\\n\", classification_report(y_test, y_pred_tuned))\n",
        "\n",
        "\n",
        "# Step 7: Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred_tuned)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n"
      ]
    }
  ]
}